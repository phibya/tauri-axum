{
  "model": "test-llama",
  "messages": [
    {
      "role": "user", 
      "content": "Hello! Can you explain what paged attention is?"
    }
  ],
  "max_tokens": 100,
  "temperature": 0.7,
  "stream": false
}